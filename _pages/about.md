---
permalink: /
title: "Home"
excerpt: "About me"
author_profile: true
classes: wide
redirect_from: 
  - /about/
  - /about.html
---

I am an associate professor in State Key Laboratory of Processors (SKLP), Institute of Computing Technology (ICT), Chinese Academy of Sciences (CAS). I got my B.Eng degree and M.Eng degree from Harbin Institute of Technology, and Ph.D degree from The University of Hong Kong advised by Prof. Hayden So in 2016. I worked as a research fellow in National University of Singapore from 2016 to 2018, and thereafter, I joined ICT as an associate professor. My current research interest focuses on domain specific architecture and system, LLM for Chip Design.


## Vancancies
I am looking for self-motivated master/intern students for LLM-based intelligent chip designs. It includes various design tasks such as RISC-V SoC design and verification, RISC-V ASIP design automation, domain-specific accelerator generation, Low-power design and optimization. Students with RISC-V processor design and LLM experience are highly preferred. It is possible to work fully remotely. Check the topics in the following list and contact me if you are interested.
- LLM-based SoC/DSA/ASIP design
- LLM-based high-level synthesis
- LLM-based ASIC design, verification, and debugging
- LLM-based EDA parallelization


<!-- <address>
  UCL Centre for Artificial Intelligence<br />Office 1.25L<br />90 High Holborn<br /> WC1V 6LJ London<br /> United Kingdom
</address>
<br> -->

<!-- ([see on Google Maps](https://goo.gl/maps/5JmzYNJTt8hZufbZA)) -->

<!-- <iframe src="https://www.google.com/maps/embed?pb=!1m14!1m8!1m3!1d4965.579778013099!2d-0.12450412319706675!3d51.51707062522409!3m2!1i1024!2i768!4f13.1!3m3!1m2!1s0x48761b3585a9c137%3A0xffe1d0c346654ca5!2s90%20High%20Holborn%2C%20Holborn%2C%20London%20WC1V%206LJ!5e0!3m2!1sfr!2suk!4v1588107506410!5m2!1sfr!2suk" width="600" height="450" frameborder="0" style="border:0;" allowfullscreen="" aria-hidden="false" tabindex="0"></iframe> -->


<!-- I obtained a Ph.D. in mathematics in 2013 from [UPMC](http://www.upmc.fr/) (Université Pierre & Marie Curie, France) under the supervision of [Gérard Biau](http://www.lsta.upmc.fr/biau.html) and [Éric Moulines](https://scholar.google.fr/citations?user=_XE1LvQAAAAJ&hl=fr). Prior to that, I was a research assistant at [DTU Compute](http://www.compute.dtu.dk/) (Denmark) supervised by [Gilles Guillot](http://www2.imm.dtu.dk/~gigu/#).
 -->

<!-- My main line of research is in statistical machine learning. I am primarily interested in the design, analysis and implementation of statistical learning methods for high dimensional problems. My interests include (but are not limited to): PAC-Bayesian theory, sparsity and high-dimensional statistics, optimisation theory, statistical learning theory, non-negative matrix factorisation, aggregation of estimators and classifiers, MCMC algorithms, (un)supervised learning, online clustering, concentration inequalities... -->


## News
- [Jun 2020] Shengwen Liang and Rick Lee won the Third Prize (FPGA Track) of the 2020 IEEE Low-Power Computer Vision Challenge (LPCVC).
- [Jul 2022] Haitong Huang, Erjing Luo, and Cangyuan Li in my group got the Third Place in DAC'22 SDC.
- [Jan 2023] Our work "EnGN: A High-Throughput and Energy-Efficient Accelerator for Large Graph Neural Networks" won the Best Paper Award of TC'21.
- [Jun 2023] Congratulations! Haitong Huang, Erjing Luo, and Guoyu Li got the Second Place in DAC'23 SDC.
- [Nov 2023] A HW/SW co-design framework for mixed-precision neural network acceleration on FPGAs (DeepBurning-MixQ) is accepted by ICCAD'23. We are adding LLM support to enable more intelligent code generation. The code is open sourced on github and welcome to try it.
- [Mar 2024] A multi-resolution fault injection framework for deep learning is accepted by TVLSI'24. It is well documented and validated sufficiently, and provides many convenient evaluation features that are typically required in fault-tolerant deep learning study. Check it on github.
- [Jun 2024] HLSPilot: LLM-based High-level Synthesis is accepted by ICCAD'24. This work presents an LLM-based high-level synthesis design framework for typical CPU-FPGA architecture. Particularly, it leverages LLM and RAG techniques to generate HLS-based accelerator design for arbitrary sequential C/C++ code, which is also a key component for our LLM-driven SoC generation framework.

## Fundings
- HW/SW platform for intelligent cross-layer design and optimization of processors, 11 000 000￥, xdb(2024-2028)
- Natural weather disturbed image generation for remote sensing, 500 000￥, XXX(2023-2024)
- AI assisted DSA design automation, 300 000￥, SKLP(2023-2024)
- Automatic Cross-Layer DSA Design and Optimization, 1 600 000￥, National Key Research and Development Program of China(2023-2025)
- Intelligent In-Storage Big Data Processing System, 1 300 000￥, 1XX(2023-2024)
- Fault-tolerant Deep Learning Toolchain for COTS Devices, 300 000￥, XXX(2023)
- Elastic Fault-tolerant Deep Learning Processor Design, 570 000￥, NSFC(2022-2025)
- Customized Energy-efficient Graph Processing Acceleration on FPGAs, 300 000￥, NSFC(2020-2022)
- Fault-tolerant Deep Learning Processor Design Automation, 300 000￥, SKLCA(2021-2022)

## Talks
- 基于大语言模型的全自动CPU-FPGA异构硬件加速, 高性能异构计算与人工智能优化论坛，CCF-HPC, 2024
- 异构硬件加速器设计、优化以及编程, 高性能异构计算与人工智能优化论坛，CCF-HPC，2023
- 基于计算存储器的图处理系统设计, 面向复杂图计算应用的新型高能效体系结构论坛，CNCC，2022
- 容错深度学习处理器微结构设计，集成电路设计与自动化学术会议(CCF-DAC), 2021
- DeepBurning2.0: An Automatic End-to-end Neural Network Acceleration System on FPGAs, 华南理工大学，软件学院, 2019

## Services
- PC for DFTS'22, FPT'22, ITC'22
- PC for ATS'23, FPT'23, DFTS'23, ITC'23, NeurIPS'23
- PC for DFTS'24, FPT'24, ICLR'24, FCCM'24, ICML'24
- Review for TC, TPDS, TCAD. TVLSI, TETC, JETC, JSA, TNNLS

## Graduated Students
- Zheng Feng (Master student, Huawei, AI Compilation)
- Guoyu Li (Master student, Baidu, Kunlun Chip)
- Haitong Huang (Master student, Tencent, AI Lab)
- Xuejian Sun (Intern from Harbin Institute of Technology, Master student in Fudan University)
- Erjing Luo (Intern from Beijing Institute of Technology, Mphil in University of Alberta)
- Miaoxin Wang (Intern from Harbin Institute of Technology, Master student in Nanjing University)
- Jinming Zhao (Intern from Wuhan University, PhD candidate in the University of Hong Kong)
- Zhiyu Zhu (Intern from Harbin Institute of Technology, CETC 47)
- Cheng Chu (Intern from Hefei University of Technology, PhD candidate in Indiana University Bloomington)
- Meng He (Intern from Hefei University of Technology, 字节跳动)
- Ziyang Zhu (Intern from Hefei University of Technology, 紫光展锐)
- Qiang Zhang (Master Student, 快手)
- Kouzi Xing (Intern from Hefei University of Technology, 商汤科技)
- Li Li (Intern from Hefei University of Technology, 京东)
- Kexin Chu (Intern from Hefei University of Technology, 百度)
- Kaijie Tu (Intern from Hefei University of Technology, 计算所)
- Chang Shi (Master student, Alibaba)
- Peibin Wu (Master student, MSRA)

<!-- ## News

<div class="grid__wrapper">
{% for post in site.posts limit:12 %}  
    {% include archive-single.html type="grid" %}
{% endfor %}
</div>
 -->
