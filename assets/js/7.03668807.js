(window.webpackJsonp=window.webpackJsonp||[]).push([[7],{208:function(e,r,n){"use strict";var t=n(72);n.n(t).a},223:function(e,r,n){"use strict";n.r(r);n(208);var t=n(0),o=Object(t.a)({},(function(){var e=this,r=e.$createElement,n=e._self._c||r;return n("ContentSlotsDistributor",{attrs:{"slot-key":e.$parent.slotKey}},[n("ProfileSection",{attrs:{frontmatter:e.$page.frontmatter}}),e._v(" "),n("h2",{attrs:{id:"about-me"}},[e._v("About Me")]),e._v(" "),n("p",[e._v("I am an associate professor in "),n("a",{attrs:{href:"https://things.ac.cn",target:"_blank",rel:"noopener noreferrer"}},[e._v("ThingsLAB"),n("OutboundLink")],1),e._v(" in Institute of Computing Technology, Chinese Academy of Sciences. I got my Ph.D degree in Department of Electrical and Electronic Engineering at The University of Hong Kong in 2016, advised by "),n("a",{attrs:{href:"http://www.eee.hku.hk/~hso",target:"_blank",rel:"noopener noreferrer"}},[e._v("Prof. Hayden Kwok-Hay So"),n("OutboundLink")],1),e._v(" and "),n("a",{attrs:{href:"http://www.eee.hku.hk/~nwong",target:"_blank",rel:"noopener noreferrer"}},[e._v("Prof. Ngai Wong"),n("OutboundLink")],1),e._v(". Then I worked as a research fellow in Xtra group led by "),n("a",{attrs:{href:"https://www.comp.nus.edu.sg/~hebs/",target:"_blank",rel:"noopener noreferrer"}},[e._v("Prof. Bingsheng He"),n("OutboundLink")],1),e._v(" in School of Computing, National University of Singapore from 2016 to 2018. My research interest includes reconfigurable computing, customized computing and FPGA-based hardware acceleration for domain specific applications like deep learning and graph processing.")]),e._v(" "),n("h2",{attrs:{id:"news"}},[e._v("News")]),e._v(" "),n("ul",[n("li",[e._v('[Jan 2020] Our paper "BitPruner: Network Pruning for Bit-Serial Accelerators" is accepted by DAC\'20.')]),e._v(" "),n("li",[e._v('[May 2020] Our paper "Persistent Fault Analysis of Neural Networks on FPGA-based Acceleration System" is accepted by ASAP\'2020')]),e._v(" "),n("li",[e._v('[June 2020] Our paper "Accelerating Generative Neural Networks on Unmodified Deep Learning Processors - A Software Approach" is accepted by Special Issue on Domain-Specific Architectures for Emerging Applications and will appear on Transactions on Computers.')]),e._v(" "),n("li",[e._v('[July 2020] Our paper "DeepBurning-GL: An Automated Framework for GeneratingÂ  Graph Neural Network Accelerators" is accepted by ICCAD\'20')]),e._v(" "),n("li",[e._v('[August 2020] Our paper "EnGN: A High-Throughput and Energy-Efficient Accelerator for Large Graph Neural Networks" is accepted by IEEE Transactions on Computers.')]),e._v(" "),n("li",[e._v('[August 2020] Our paper "A Hybrid Computing Architecture for Fault-tolerant Deep Learning Accelerators" is accepted by ICCD 2020.')])]),e._v(" "),n("h2",{attrs:{id:"education"}},[e._v("Education")]),e._v(" "),n("ul",[n("li",[e._v("Ph.D. in Computer Engineering, The University of Hong Kong, 2011-2016")]),e._v(" "),n("li",[e._v("M.Eng. in Electronic Engineering, Harbin Institute of Technology, 2007-2009")]),e._v(" "),n("li",[e._v("B.Eng. in Electronic Engineering, Harbin Institute of Technology, 2003-2007")])]),e._v(" "),n("h2",{attrs:{id:"projects"}},[e._v("Projects")]),e._v(" "),n("ul",[n("li",[e._v("DeepBurning: automatic generation of FPGA-based learning accelerators for the neural network family")]),e._v(" "),n("li",[e._v("QuickDough: a rapid loop acceleration on closely coupled CPU-FPGA architectures")]),e._v(" "),n("li",[e._v("Large-scale graph processing on heterogeneous CPU-FPGA architectures")])]),e._v(" "),n("h2",{attrs:{id:"services"}},[e._v("Services")]),e._v(" "),n("ul",[n("li",[e._v("Review for:\n"),n("ul",[n("li",[e._v("IEEE Transactions on Very Large Scale Integration (TVLSI)")]),e._v(" "),n("li",[e._v("Journal of Computer Methods and Programs in Biomedicine\n")])])])])],1)}),[],!1,null,null,null);r.default=o.exports},72:function(e,r,n){}}]);