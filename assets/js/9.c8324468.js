(window.webpackJsonp=window.webpackJsonp||[]).push([[9],{208:function(e,t,r){"use strict";var o=r(72);r.n(o).a},223:function(e,t,r){"use strict";r.r(t);r(208);var o=r(0),n=Object(o.a)({},(function(){var e=this,t=e.$createElement,r=e._self._c||t;return r("ContentSlotsDistributor",{attrs:{"slot-key":e.$parent.slotKey}},[r("h2",{attrs:{id:"projects"}},[e._v("Projects")]),e._v(" "),r("ProjectCard",[r("p",[r("strong",[e._v("LLM-based SoC Design Tools")]),e._v(" (Ongoing)\nLLMs with powerful imitation and learning capability can not only handle tedious and repetitve work but also address more complex work that requires expertise and experiences. SoC design that consists of a set of connected standard IPs actually become a possible task for LLMs. We investigate the use of LLM for SoC design with a top-down approach ranging from  architecture design, IP integration, processor customization, accelerator generation, SoC debug and verification.")])]),e._v(" "),r("ProjectCard",[r("p",[r("strong",[e._v("Graph Processing Accelerators and Systems")]),e._v(" (Ongoing)\nGraph processing is notorously difficult because of the irregular accesses and low compute-to-I/O ratio. We mainly investigate graph processing accelerators and processing systems on new hardware such as computational storage and heterogeneous architectures to address the computing challenge. In addition, we also extend our work to more graph-based algorithms and systems such as vector retrieval and graph learning.")]),e._v(" "),r("p",[e._v("["),r("a",{attrs:{href:"https://anonymous.4open.science/r/TaijiGraph2022",target:"_blank",rel:"noopener noreferrer"}},[e._v("TaijiGraph: single node out-of-core graph processing system based on computational storage"),r("OutboundLink")],1),e._v("]")])]),e._v(" "),r("ProjectCard",[r("p",[r("strong",[e._v("Robust Deep Learning")]),e._v(" (Ongoing)")]),e._v(" "),r("p",[e._v("We mainly investigate the design of deep learning toolchains all the way from deep learning applications to low-level circuit designs. Specifically, we explore model-independent fault-tolerant algorithm design, model-dependent fault-tolerant algorithm design, fault-tolerant compilation, fault-tolerant architecture design, fault-tolerant circuit design, and cross-layer fault-tolerant designs. In addition, we also develop a set of fault injection tools from different perspectives to assist fault-tolerant design at different abstraction levels.")]),e._v(" "),r("p",[e._v("["),r("a",{attrs:{href:"https://github.com/fffasttime/MR-Neural-Network-Reliability-Analysis-Toolbox",target:"_blank",rel:"noopener noreferrer"}},[e._v("Multi-Resolution Fault Injection Tools"),r("OutboundLink")],1),e._v("]")])]),e._v(" "),r("ProjectCard",[r("p",[r("strong",[e._v("Domain-Specific Accelerator Design Tools (Ongoing)")])]),e._v(" "),r("p",[e._v("We investigate DSA design automation approaches from different perspectives including HLS template based frameworks, hardware overlays, and domain specific languages. In order to optimize the resulting DSAs, DSE tools are also explored and integrated.")]),e._v(" "),r("p",[e._v("["),r("a",{attrs:{href:"https://anonymous.4open.science/r/NASPacking-8B1F/",target:"_blank",rel:"noopener noreferrer"}},[e._v("Mixed Precision Neural Network Acceleration on FPGAs"),r("OutboundLink")],1),e._v("]")]),e._v(" "),r("p",[e._v("["),r("a",{attrs:{href:"https://github.com/Liu-Cheng/bfs_with_Intel_OpenCL.git",target:"_blank",rel:"noopener noreferrer"}},[e._v("BFS Acceleration with Intel OpenCL"),r("OutboundLink")],1),e._v("]")])]),e._v(" "),r("ProjectCard",[r("p",[r("strong",[e._v("DeepBurning: Automatic generation of FPGA-based learning accelerators for the neural network family")]),e._v(" (2018-2020)")]),e._v(" "),r("p",[e._v("DeepBurning is an end-to-end automatic neural network accelerator design tool for specialized learning tasks. It provides a unified deep learning acceleration solution to high-level application designers without dealing with the model training and hardware accelerator tuning. You can refer to DeepBurning homepage for more details.")]),e._v(" "),r("p",[e._v("["),r("a",{attrs:{href:"https://github.com/groupsada/DeepBurning",target:"_blank",rel:"noopener noreferrer"}},[e._v("DeepBurning Project"),r("OutboundLink")],1),e._v("]")]),e._v(" "),r("p",[e._v("["),r("a",{attrs:{href:"https://github.com/fffasttime/AnyPackingNet.git",target:"_blank",rel:"noopener noreferrer"}},[e._v("DeepBurning-MixQ Project"),r("OutboundLink")],1),e._v("]")])]),e._v(" "),r("ProjectCard",[r("p",[r("strong",[e._v("QuickDough: A rapid loop acceleration on closely coupled CPU-FPGA architectures")]),e._v(" (2011-2016)")]),e._v(" "),r("p",[e._v("QuickDough is developed to address the FPGA design productivity problem. By utilizing a soft coarse-grained reconfigurable array (SCGRA) overlay built on top of off-the-shelf FPGAs, it compiles a high-level loop to the overlay through a rapid operation scheduling first and then generates the FPGA accelerator bitstream through a rapid integration of the scheduling result and a pre-built overlay bitstream.")]),e._v(" "),r("p",[e._v("["),r("a",{attrs:{href:"https://github.com/Liu-Cheng/QuickDough",target:"_blank",rel:"noopener noreferrer"}},[e._v("QuickDough Project"),r("OutboundLink")],1),e._v("]")])])],1)}),[],!1,null,null,null);t.default=n.exports},72:function(e,t,r){}}]);